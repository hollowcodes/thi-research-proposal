
\documentclass[journal]{IEEEtran}


\usepackage[utf8]{inputenc}




\begin{document}

\title{loss weighting for learnability imbalance in multiclass-classification}



\author{Theodor Peifer
        \linebreak
        thp7219@thi.de
        \linebreak
        Technische Hochschule Ingolstadt
}



\maketitle


\begin{abstract}
Neural Networks have proven themselves to be powerful classification 
tools by solving problems in a range of domains with high accuracy. 
But especially when it comes to multi-class classification the accuracy is never evenly distributed across all classes, which means that the true-positive rate for each class is different.
This can happen even in a balanced dataset since some classes are more difficult to learn my the model than others (this phenomenon is further referred to as "learnability imbalance").
Learnability imbalance can occur for a variety of reasons, such as when the similiarity of two classes is high or when the quality of data for one class is worse than others.
A common way to address this problem is to give a weight to the loss function for each class to penalize losses of certain classes higher or lower. 
This research will address the determination of such weights to counteract the learning imbalance of balanced data sets.
\end{abstract}


\section{Introduction}
TODO Introduction here


\section{first section}
TODO first section here


\section{second section}
TODO second section here


\section{third section}
TODO third section here


\begin{thebibliography}{1}

\bibitem{}
Name Name, Name Name, Name Name (2006). Title, 24(1), 29-33.

\end{thebibliography}


\end{document}